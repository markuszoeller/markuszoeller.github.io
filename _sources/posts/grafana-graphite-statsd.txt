

.. post::
   :tags: data-visualization, how-to
   :title: Setup Grafana + Graphite + statsd


=================================
Setup Grafana + Graphite + statsd
=================================

.. todo:: add a useful abstract

* no details about statsd, graphite or grafana
* get things running fast without fakes and mocks
* be "build my dashboard" ready in 15 minutes

.. contents::
    :local:
    :backlinks: top

Environment
===========

.. todo:: specify that a little

* only Ubuntu 14.04 because of *synthesize*
* virtual machine hosted by digital ocean
* only PoC, not productive

Step-by-Step
============

.. highlight:: bash

change the timezone to UTC-0, everything else is confusing::

    $ dpkg-reconfigure tzdata

We need git to clone the helper scripts::

    $ apt-get install -y git

*Synthesize* [1]_ installs statsd and graphite for us::

    $ mkdir /opt/synthesize
    $ cd /opt/synthesize
    $ git clone https://github.com/obfuscurity/synthesize
    $ cd /opt/synthesize/synthesize
    $ ./install


Install ``grafana`` from package [2]_ (it's not in the official repos)::

    $ wget https://grafanarel.s3.amazonaws.com/builds/grafana_2.6.0_amd64.deb
    $ apt-get install -y adduser libfontconfig
    $ dpkg -i grafana_2.6.0_amd64.deb

Allow anonymous access with *viewer* rights [3]_. Users which are *not* logged
in can create dashboards but cannot save them.::

    $ vim /etc/grafana/grafana.ini

.. code-block:: ini

    [auth.anonymous]
    enabled = true
    org_role = viewer

Everything is set up, start the engines::

    $ service grafana-server start

Open the grafana dashboard with your browser and use port ``3000`` in the URL.
That's the admin URL which is necessary to save your created dashboards.

.. todo:: Add an annotated picture here, the list is bad

Add as datasource:

* Name: my-graphite
* Type: Graphite
* Url: https://127.0.0.01
* Access: proxy
* Basic Auth: checked
* With Credentials: checked
* User: admin
* Password: graphite_me_synthesize

The Grafana dashboard is intuitive and you can build graphs easily.
There are already some metrics about the host machine.

.. todo:: show an example query in Grafana here to give a hint

You can also access the web UI of the underlying *graphite* at
port ``80``. The hierarchy of the metrics is shown there in a nice
way.

If you want to push your own metrics, below is an example.
It queries information about *OpenStack Nova* bugs from Launchpad and
pushes it to *statsd*. It's a simplified version of a PoC I made
which I intend to make part of http://grafana.openstack.org/.
The key parts of the code are highlighted.

Install these prerequisites before we go to the script::

    $ pip install launchpadlib
    $ pip install python-statsd

Create the folder for the statsd script::

    $ mkdir /opt/lp_stats
    $ cd /opt/lp_stats

.. todo:: double-check if this code works

Get the script ``bug_stats.py`` which creates the statsd data

.. code-block:: python
    :linenos:
    :emphasize-lines: 6,61,63

    #!/usr/bin/env python

    from launchpadlib.launchpad import Launchpad

    import os
    import statsd
    import sys


    class BugStatsCollector(object):
        """Collect bug stats by Launchpad project name """

        LP_IMPORTANCES = ["Undecided", "Wishlist", "Low",
                          "Medium", "High", "Critical"]

        def __init__(self, project_name):
            self.project_name = project_name

            cachedir = os.path.expanduser("~/.launchpadlib/cache/")
            if not os.path.exists(cachedir):
                os.makedirs(cachedir, 0o700)
            launchpad = Launchpad.login_anonymously('bugstats',
                                                    'production',
                                                    cachedir)
            self.project = launchpad.projects[self.project_name]

        def get_open_by_importance(self):
            """Return the stats for open bugs, separated by importance.

            :rtype: list of 2-tuple key-value pairs
            """
            importance_stats = []
            for importance in BugStatsCollector.LP_IMPORTANCES:
                bug_tasks = self.project.searchTasks(
                    status=BugStatsCollector.LP_OPEN_STATUSES,
                    importance=importance,
                    omit_duplicates=True)
                stats_key = self._get_valid_stat_key_name(importance)
                stats_value = self._count_bug_tasks(bug_tasks)
                stat =(stats_key, stats_value)
                importance_stats.append(stat)
            return importance_stats

        def _get_valid_stat_key_name(self, name):
            stat_key = name
            stat_key = stat_key.replace(" ", "").lower()
            stat_key = stat_key.replace("(", "-")
            stat_key = stat_key.replace(")", "")
            return stat_key

        def _count_bug_tasks(self, bug_tasks):
            return int(bug_tasks._wadl_resource.representation['total_size'])


    def push_to_statsd(metric_name, bug_stats):
        """push bug statistics to statsd on this host machine

        :param metric_name: The name of the metric
        :param bug_stats: list of 2-tuple key-value pairs to push
        """
        gauge = statsd.Gauge(metric_name)
        for bug_stat in bug_stats:
            gauge.send(bug_stat[0], bug_stat[1])


    if __name__ == '__main__':
        projects = ['nova', 'python-novaclient', 'cinder', 'neutron']
        for project_name in projects:
            collector = BugStatsCollector(project_name)
            metric_name = 'launchpad.bugs.%s.open-by-importance' % project_name
            bug_stats = collector.get_open_by_importance()
            push_to_statsd(metric_name, bug_stats)

This script will create this hierarchy in *graphite*:

.. image:: ../images/graphite_gauges.jpg
   :alt: The statsd gauges displayed in graphite
   :target: ../../_images/graphite_gauges.jpg


.. todo:: replace that above with a picture from graphite

The leaves of this tree will be filled with the values we provide attached
to a timestamp *statsd* will get from the host. That's why setting the
timezone from the beginning is important. Running this script multiple times
will create the time series data we want to visualize with *Grafana*.

Run ``bug_stats.py`` in an interval of 5 minutes as ``nohup`` to avoid
interruption when the SSH session terminates::

    $ nohup watch -n 300 python bug_stats.py &


Conclusion
==========

Provided with the steps above you should get a running playground in around
15 minutes. All the pieces work together without any fakes or mocks. Playing
around with your custom time series data and its visualization with *Grafana*
for PoCs should now be easier.

References
==========

.. [1] https://github.com/obfuscurity/synthesize/
.. [2] http://docs.grafana.org/installation/debian/
.. [3] http://docs.grafana.org/installation/configuration/

